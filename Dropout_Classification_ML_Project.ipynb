{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Istalling libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Nonyi1XO9U"
      },
      "source": [
        "**Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45XlnyXeVq11"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Modelling\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.stats import randint\n",
        "\n",
        "#Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1oalmCqXWWl"
      },
      "source": [
        "**Import CSV file in python and display data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "XGD73cAIV4h1",
        "outputId": "58d5acee-d5c7-4246-b806-b1949d5b0e5a"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('Data/data.csv', sep=';')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNL9R9kfXiry"
      },
      "source": [
        "**Display taregt values and count**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH2fUaxIV8hp",
        "outputId": "ae896000-7edc-48f2-f885-e6a575834f7a"
      },
      "outputs": [],
      "source": [
        "data['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOBFWTJnXoSm"
      },
      "source": [
        "**Divide the data into input and outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWhKoDMMWFH6"
      },
      "outputs": [],
      "source": [
        "inputs = data.drop(['Target'], axis = 1)\n",
        "target = data['Target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAAv6cvPXpFZ"
      },
      "source": [
        "**Split the data into training and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9afzgK_WQC_"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(inputs,\n",
        "                                                   target,\n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state = 365,\n",
        "                                                   stratify = target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zewTV2qa1y1K"
      },
      "source": [
        "**Encoding target labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92JpMn1k1zDH",
        "outputId": "e9fa95c8-a3d9-4f47-b385-ea24351740bf"
      },
      "outputs": [],
      "source": [
        "enc_t = LabelEncoder()\n",
        "y_train = enc_t.fit_transform(y_train)\n",
        "y_test = enc_t.transform(y_test)\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yoACBvb2aqg",
        "outputId": "8618d767-6e70-42aa-da20-41255b71307a"
      },
      "outputs": [],
      "source": [
        "integer_mapping = {l: i for i, l in enumerate(enc_t.classes_)}\n",
        "integer_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgOq_OLzWSdj"
      },
      "outputs": [],
      "source": [
        "\n",
        "SelectedClassifier = input(\"Select your classifier, KNN-Baseline or RandomForest\")\n",
        "print(SelectedClassifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoJtyp1lX48X"
      },
      "source": [
        "**Using the test data to predict the labels. This will be used to find the performance of the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cUfHr8JWUVe",
        "outputId": "754ecfe9-a194-4845-f1ce-ff85e2838f4d"
      },
      "outputs": [],
      "source": [
        "def run_classifier(x_train, x_test, y_train, y_test, SelectedClassifier):\n",
        "    if SelectedClassifier == \"KNN-Baseline\":\n",
        "        clf = KNeighborsClassifier(n_neighbors=5)\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "    elif SelectedClassifier == \"RandomForest\":\n",
        "        rf = RandomForestClassifier(random_state=365, ccp_alpha=0.001)\n",
        "        rf.fit(x_train, y_train)\n",
        "        y_pred = rf.predict(x_test)\n",
        "    else:\n",
        "        print(\"No Classifier Selected\")\n",
        "        return None\n",
        "\n",
        "    precision = precision_score(y_test, y_pred, average=\"micro\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"micro\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "\n",
        "    # Calculate micro-average\n",
        "    micro_precision = precision\n",
        "    micro_recall = recall\n",
        "    micro_f1 = f1\n",
        "\n",
        "    print(\"Micro-average Precision: {:.2f}\".format(micro_precision))\n",
        "    print(\"Micro-average Recall: {:.2f}\".format(micro_recall))\n",
        "    print(\"Micro-average F1-Score: {:.2f}\".format(micro_f1))\n",
        "    print(\"======================================\")\n",
        "    print(\"=======CLASSIFICATION SUMMARY=========\")\n",
        "    print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resampling the minority class. The strategy can be changed as required.\n",
        "sm = SMOTE(sampling_strategy='auto', k_neighbors=20, n_jobs=4, random_state=365)\n",
        "\n",
        "x_resampled, y_resampled = sm.fit_resample(x_train, y_train)\n",
        "unique, counts = np.unique(y_resampled_enc, return_counts=True)\n",
        "\n",
        "classificationReport = run_classifier(x_resampled, x_test, y_resampled, y_test,SelectedClassifier=SelectedClassifier)\n",
        "print(classificationReport)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCnvbGDFOlIU"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "HNLQHkobOlQ1",
        "outputId": "12612944-186e-4e36-9a9e-577269d89840"
      },
      "outputs": [],
      "source": [
        "def run_hyperparameters(x_train, y_train):\n",
        "    ####### KNN\n",
        "    # ##Define the parameter space for KNN\n",
        "    # print(len(x_train.columns))\n",
        "    if SelectedClassifier == \"KNN-Baseline\":\n",
        "        param_dist_knn = {\n",
        "            'n_neighbors': randint(36,37),  # Number of neighbors to consider\n",
        "            'p': [1, 2],  # 1 for Manhattan distance (L1), 2 for Euclidean distance (L2)\n",
        "            'weights': ['uniform', 'distance']  # Weighting strategy\n",
        "        }\n",
        "        # Create a KNN classifier\n",
        "        knn = KNeighborsClassifier()\n",
        "        # Use random search to find the best hyperparameters\n",
        "        rand_search = RandomizedSearchCV(knn,\n",
        "                                            param_distributions=param_dist_knn,\n",
        "                                            n_iter=5,\n",
        "                                            cv=5)\n",
        "\n",
        "        # Fit the random search object to the data\n",
        "        rand_search.fit(x_train, y_train)\n",
        "    ######## RANDOM FOREST\n",
        "    elif SelectedClassifier == \"RandomForest\":\n",
        "        param_dist = {'n_estimators': randint(50,500), 'max_depth': randint(1,20)}\n",
        "\n",
        "        # Create a random forest classifier\n",
        "        rf = RandomForestClassifier()\n",
        "\n",
        "        # # Use random search to find the best hyperparameters\n",
        "        rand_search = RandomizedSearchCV(rf,\n",
        "                                        param_distributions = param_dist,\n",
        "                                        n_iter=5,\n",
        "                                        cv=5)\n",
        "\n",
        "        # Fit the random search object to the data\n",
        "        rand_search.fit(x_train, y_train)\n",
        "    else:\n",
        "        print(\"No Classifier Selected\")\n",
        "        return None\n",
        "    \n",
        "    return rand_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_search= run_hyperparameters(x_resampled,y_resampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJYaV64PR9b"
      },
      "source": [
        "**Classification report for different parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzQMj_xzQUUo",
        "outputId": "1af76cc5-ce62-49b3-9913-b96a444ac142"
      },
      "outputs": [],
      "source": [
        "# Create a variable for the best model\n",
        "best_rf = rand_search.best_estimator_\n",
        "print('Best parameters set found on development set: ')\n",
        "print(rand_search.best_params_)\n",
        "print()\n",
        "\n",
        "means = rand_search.cv_results_['mean_test_score']\n",
        "stds = rand_search.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, rand_search.cv_results_['params']):\n",
        "    print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
        "print()\n",
        "\n",
        "print('Detailed classification report:')\n",
        "print()\n",
        "print('The model is trained on the full development set.')\n",
        "print('The scores are computed on the full evaluation set.')\n",
        "print()\n",
        "y_true, y_pred = y_test, rand_search.predict(x_test)\n",
        "precision = precision_score(y_test, y_pred, average=\"micro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"micro\")\n",
        "f1 = f1_score(y_test, y_pred,average=\"micro\")\n",
        "\n",
        "# Calculate micro-average\n",
        "micro_precision = precision.mean()\n",
        "micro_recall = recall.mean()\n",
        "micro_f1 = f1.mean()\n",
        "\n",
        "print(\"Micro-average Precision: {:.2f}\".format(micro_precision))\n",
        "print(\"Micro-average Recall: {:.2f}\".format(micro_recall))\n",
        "print(\"Micro-average F1-Score: {:.2f}\".format(micro_f1))\n",
        "print(\"======================================\")\n",
        "print(\"=======CLASSIFICATION SUMMARY=========\")\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zqRagOMSzxS"
      },
      "source": [
        "**Finding important features in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "hE4-k2_zSz49",
        "outputId": "03865b03-fb50-4912-b5ed-114e1a104782"
      },
      "outputs": [],
      "source": [
        "if SelectedClassifier ==\"KNN-Baseline\":\n",
        "    best_knn = rand_search.best_estimator_\n",
        "    best_knn.fit(x_train, y_train)\n",
        "    # Get the distance matrix from each data point to its k-nearest neighbors\n",
        "    distances, indices = best_knn.kneighbors(x_train)\n",
        "    # Analyze the feature relevance based on distances to neighbors\n",
        "    # For example, you can calculate the average distance for each feature\n",
        "    feature_relevance = distances.mean(axis=0)\n",
        "\n",
        "    # Create a Series to visualize the feature relevance\n",
        "    feature_relevance_series = pd.Series(feature_relevance, index=x_train.columns).sort_values(ascending =False)\n",
        "\n",
        "    # Plot a bar chart for feature relevance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    feature_relevance_series.plot.bar()\n",
        "    plt.title('Feature Relevance in KNN')\n",
        "    plt.show()\n",
        "elif SelectedClassifier == \"RandomForest\":\n",
        "    #FOR RANDOM SEARCH\n",
        "    # Create a series containing feature importances from the model and feature names from the training data\n",
        "    feature_importances = pd.Series(best_rf.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
        "    # Plot a simple bar chart\n",
        "    plt.figure(figsize=(10,6))\n",
        "    feature_importances.plot.bar();\n",
        "else:\n",
        "    print(\"No Classifier selected\")\n",
        "\n",
        "for i in data.columns:\n",
        "  sns.displot(data=data, x=i, height=4)\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
